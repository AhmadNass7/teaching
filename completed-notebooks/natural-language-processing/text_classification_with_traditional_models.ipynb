{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55745315",
   "metadata": {},
   "source": [
    "# Text Classification with Traditional Models\n",
    "\n",
    "The Twitter dataset (`tweets.csv`) was scraped from February of 2015 for sentiment analysis on US airline tweets. Contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\"). The dataset can be found [here.](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)\n",
    "\n",
    "We want to train a supervised machine learning model that, given each new tweet, predicts the sentiment class of that tweet (i.e., positive, negative, or neutral). You should choose a traditional classification model, such as Naive Bayes, but try out different feature representation approaches to optimize the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c1fff",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d6ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import gensim.models\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.model_selection\n",
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e68bf",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf4eaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"../../datasets/tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b740e",
   "metadata": {},
   "source": [
    "## Splitting the Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2080191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"text\"]\n",
    "y = df[\"airline_sentiment\"]\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5320e0",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7954b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_x_train: (10980, 2590)\n",
      "new_x_test: (3660, 2590)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(min_df=5)\n",
    "vectorizer.fit(x_train)\n",
    "\n",
    "new_x_train = vectorizer.transform(x_train).toarray()\n",
    "new_x_test = vectorizer.transform(x_test).toarray()\n",
    "\n",
    "print(\"new_x_train:\", new_x_train.shape)\n",
    "print(\"new_x_test:\", new_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b61e6",
   "metadata": {},
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde42659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.naive_bayes.MultinomialNB()\n",
    "model.fit(new_x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6d2d7",
   "metadata": {},
   "source": [
    "## Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092bb6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.73\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(new_x_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_predicted)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96ec87",
   "metadata": {},
   "source": [
    "## Predicting Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5da88e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = [\"This is a very bad airline!\", \"I love your good flights.\"]\n",
    "encoded_tweets = vectorizer.transform(tweets).toarray()\n",
    "predicted_class = model.predict(encoded_tweets)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead2ac8",
   "metadata": {},
   "source": [
    "# An Alternative Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03eaf0",
   "metadata": {},
   "source": [
    "### Loading the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4fe0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"/tmp/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2b2c1",
   "metadata": {},
   "source": [
    "### Caculate average word embdding vectors for tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da46a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_word_embedding = []\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "for tweet in df[\"text\"]:\n",
    "    words = tokenizer.tokenize(tweet)\n",
    "    feature_vector = numpy.zeros(300)\n",
    "    ctr = 0\n",
    "    for word in words:\n",
    "        if word in word2vec_model and word not in stop_words:\n",
    "            feature_vector += word2vec_model[word]\n",
    "            ctr += 1\n",
    "    if ctr > 0:\n",
    "        feature_vector /= ctr\n",
    "    x_word_embedding.append(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ed85b",
   "metadata": {},
   "source": [
    "### Splitting and training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d3c2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x_word_embedding, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c02a5",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aebc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "model.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a565b2",
   "metadata": {},
   "source": [
    "### Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "610ace6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.74\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(x_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_predicted)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66984364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
